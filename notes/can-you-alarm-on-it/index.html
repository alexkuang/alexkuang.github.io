<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="/assets/rajdhani.css">
    <link rel="stylesheet" href="/assets/style.css">
    <link rel="stylesheet" href="/assets/prism-coldark-dark.css">

    <title>
      
        can you alarm on it? | bikeshed.coffee
      
    </title>
  </head>
  <body class="h-full antialiased">
    <div class="xl:mx-72 mx-8">
      <h1 class="mt-4 text-2xl font-semibold text-purple-800 xl:mt-8">
        <a href="/">bikeshed.coffee</a>
      </h1>

      <div class="h-full w-full my-4 xl:my-8 xl:flex xl:gap-8">
  <main class="xl:max-w-3xl mb-8 xl:mb-0 grow">
    <article class="prose xl:prose-lg">
      <h2>can you alarm on it?</h2>

      <p>There's a stock phrase I see occasionally in finance: &quot;can you trade it?&quot;  That is: if you have information or a read on
the market that's actually good, then surely you can use it to make a profitable trade.  It's a bit glib (and yes,
almost satirically capitalist) but I do like it as a litmus test.  When gathering information it's easy to get lost and
drop into consumption for consumptions' sake.  This question is a reminder of the original purpose, which in finance is:
can you trade on it?</p>
<p>This pitfall exists in a wider business context, or at least it does the tech-centric one that I've spent most time in.
In the quest to be &quot;data-driven,&quot; teams often collect all sorts of data points, carefully collate it, and arrange it
into a nice looking dashboard.  But then the efforts fizzle out.  People stop paying attention, maybe the dashboard
stops being updated.  It becomes a side comment in new hire onboarding: &quot;oh yeah, nobody really looks at that, it's
super outdated.&quot;  I suspect one reason is that the it's not actually useful.  The charts are pretty, but if you point at
one and ask, &quot;Are things going well?  How will the line move next week?&quot; answers would likely involve much hemming and
hawing.</p>
<p>There's a similar test question in the dev ops world, even if we don't say out loud it as often: &quot;can you alarm on it&quot;?
Tech systems collect all sorts of metrics, e.g. CPU usage, data storage, network traffic.  It almost comes by default
these days in the cloud.  Plus any application-specific ones we add: transactions executed, emails sent, login attempts,
etc.  These numbers are well and good and can also go in some pretty charts, but the real test is the alarm setup.  An
alarm shows that we've done the thinking to make the metrics useful.  It takes a good operator's instinct and makes it
explicit.  This threshold is &quot;business as usual,&quot; but anything outside it requires special attention: we're going viral,
or the database needs an upgrade, or there is a spammer in the system.  Someone should investigate.</p>
<p>What's the equivalent in higher level business?  What's a good litmus test for usefulness of metrics for upper
management?  The closest I've found is the <a href="https://sixsigmastudyguide.com/xmr-charts/">XmR chart</a>, but I haven't seen
it implemented first-hand.</p>

    </article>
  </main>

  

</div>

    </div>
  </body>
</html>
